# -*- coding: utf-8 -*-
"""Nifty50MomentumPredictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GweftMVrC7t1aCxKBYLB_KgdlAm-kiiz
"""

print("Hello pratham")

import pandas as pd
import numpy as np

data_1 = pd.read_csv("final_data.csv",encoding='iso-8859-1')
data_1.head()

data_1.columns

data_1.info()

data_1.describe()

data_1.head()

!pip install transformers torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification

import torch

model_name = "ProsusAI/finbert"
tokenizer = AutoTokenizer.from_pretrained(model_name)

model = AutoModelForSequenceClassification.from_pretrained(model_name)

labels = ["positive", "negative", "neutral"]

def get_finbert_sentiment(text):

  inputs = tokenizer(text,return_tensors="pt",truncation=True,padding=True)

  with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    probs = torch.softmax(logits,dim=1).flatten().tolist()

  sentiment_dict = {labels[i] : probs[i] for i in range(len(labels))}
  sentiment_dict["prediction"] =  labels[torch.argmax(logits)]


  return sentiment_dict

print(get_finbert_sentiment("Nifty 50 surges as banking stocks rally"))

sentiments = data_1["Title"].apply(get_finbert_sentiment)

data_1["sent_pos"] = sentiments.apply(lambda x: x["positive"])
data_1["sent_neg"] = sentiments.apply(lambda x: x["negative"])
data_1["sent_neu"] = sentiments.apply(lambda x: x["neutral"])
data_1["sent_predicted"] = sentiments.apply(lambda x: x["prediction"])

data_1.head()

data_1.to_csv("Data_with_sentiments.csv")

data_1["Return"] = data_1["Close"].pct_change()

data_1.head()

data_1.to_csv("Data_with_sent_returns.csv")

"""## Aggregating and converting into a normal data."""

data_1["Date"] = pd.to_datetime(data_1["Date"],dayfirst=True).dt.date

data_1["Date"]

daily_sentiment = data_1.groupby("Date").agg({
    "sent_pos" : "mean",
    "sent_neg" : "mean",
    "sent_neu" : "mean",
    "Close" : "last",
    "Volume" : "sum"
}).reset_index()

daily_sentiment.head(10)

daily_sentiment.describe()

"""## Renaming columns and stuff"""

daily_sentiment.rename(columns={
    "sent_pos" : "avg_sent_pos",
    "sent_neg" : "avg_sent_neg",
    "sent_neu" : "avg_sent_neu",

},inplace=True)

daily_sentiment

daily_sentiment["net_sentiment"] = daily_sentiment["avg_sent_pos"] - daily_sentiment["avg_sent_neg"]

daily_sentiment

daily_sentiment["Return"] = daily_sentiment["Close"].pct_change()

daily_sentiment

daily_sentiment["Target"] = (daily_sentiment["Return"].shift(-1) > 0).astype(int)

daily_sentiment

daily_sentiment.to_csv("most_imp_data.csv")

daily_sentiment["Return"] = daily_sentiment["Return"].fillna(0)

daily_sentiment

"""### Drawing graphs to visualize the data

#### Sentiment Over Time
"""

import matplotlib.pyplot as plt

plt.plot(daily_sentiment["Date"],daily_sentiment["net_sentiment"])
plt.xlabel("Dates")
plt.ylabel("Net Sentiment")
plt.show()

"""#### Sentiment vs. Market Returns"""

plt.scatter(daily_sentiment["net_sentiment"],daily_sentiment["Return"])
plt.xlabel("net_sentiment")
plt.ylabel("Returns")
plt.show()

"""## Modeling the whole data

#### Starting with Logistic regression as baseline.
"""

X = daily_sentiment.iloc[:,1:-1].values
y = daily_sentiment.iloc[:,-1].values

print(X)
print(y)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(X_scaled,y)

y_pred = model.predict(X_scaled)

y_pred

"""#### Metrics

"""

from sklearn.metrics import confusion_matrix,accuracy_score,f1_score

confusion_matrix(y,y_pred)

accuracy_score(y,y_pred)

f1_score(y,y_pred)

"""#### Tackling non-linearity with Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

random_forest = RandomForestClassifier();

random_forest.fit(X_scaled,y)

y_pred = random_forest.predict(X_scaled)

confusion_matrix(y,y_pred)

accuracy_score(y,y_pred)

f1_score(y,y_pred)

